{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from functions import *\n",
    "from twitterTokenizer import Tokenizer\n",
    "import numpy as np, random\n",
    "import subprocess \n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.layers.normalization  import BatchNormalization\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, Bidirectional, LSTM, Input, merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = load_SemEval_from_file('./data/subtaskCE.train_dev.tsv')\n",
    "X_dev, y_dev = load_SemEval_from_file('./data/subtaskCE.devtest.tsv')\n",
    "X_test, y_test = load_SemEval_SubTaskCE_Test('./data/SemEval2016-task4-test.subtask-BCDE.txt', './data/SemEval2016_task4_subtaskC_test_gold.txt')\n",
    "X_train_ternary, y_train_ternary = load_SemEval_subtaskA('./data/subtaskA.downloaded.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7292, 1368), (1778, 1368), (20632, 1368), (5500, 1368))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_additional = load_sparse_csr('./additional_features/X_train_additional.npz', )\n",
    "X_dev_additional = load_sparse_csr('./additional_features/X_dev_additional.npz', )\n",
    "X_test_additional = load_sparse_csr('./additional_features/X_test_additional.npz',)\n",
    "X_ternary_additional = load_sparse_csr('./additional_features/X_ternary_additional.npz',)\n",
    "X_train_additional.shape, X_dev_additional.shape,  X_test_additional.shape, X_ternary_additional.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train shape', (7292, 14356), 'Dev shape', (1778, 14356), 'Test shape', (20632, 14356), '14356 vocabulary terms found')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "MAX_FEATURES, MAX_LEN, BATCH_SIZE  = 11000, 30, 64\n",
    "\n",
    "tokenizer = Tokenizer(preserve_case=False)\n",
    "\n",
    "vec = CountVectorizer( ngram_range=(1,1), analyzer='word', tokenizer=tokenizer.tokenize, stop_words=None)\n",
    "vec.fit(X_train+X_train_ternary)\n",
    "\n",
    "x_train = vec.transform(X_train)\n",
    "x_train_ternary = vec.transform(X_train_ternary)\n",
    "x_dev = vec.transform(X_dev)\n",
    "x_test = vec.transform(X_test)\n",
    "\n",
    "print(\"Train shape\", x_train.shape, \"Dev shape\", x_dev.shape, \"Test shape\", x_test.shape, \"%d vocabulary terms found\"%len(vec.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_nn = np.split(x_train.indices, x_train.indptr[1:-1])\n",
    "x_train_ternary_nn = np.split(x_train_ternary.indices, x_train_ternary.indptr[1:-1])\n",
    "x_dev_nn = np.split(x_dev.indices, x_dev.indptr[1:-1])\n",
    "x_test_nn = np.split(x_test.indices, x_test.indptr[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "('X_train shape:', (7292, 30))\n",
      "('X_ternary shape:', (5500, 30))\n",
      "('X_dev shape:', (1778, 30))\n",
      "('X_test shape:', (20632, 30))\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train_nn = sequence.pad_sequences(x_train_nn, maxlen=MAX_LEN)\n",
    "x_train_ternary_nn = sequence.pad_sequences(x_train_ternary_nn, maxlen=MAX_LEN)\n",
    "x_dev_nn = sequence.pad_sequences(x_dev_nn, maxlen=MAX_LEN)\n",
    "x_test_nn = sequence.pad_sequences(x_test_nn, maxlen=MAX_LEN)\n",
    "print('X_train shape:', x_train_nn.shape)\n",
    "print('X_ternary shape:', x_train_ternary_nn.shape)\n",
    "print('X_dev shape:', x_dev_nn.shape)\n",
    "print('X_test shape:', x_test_nn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(\"./data/\", 'glove.twitter.27B.50d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((len(vec.vocabulary_) + 1, EMBEDDING_DIM))\n",
    "for key,val in vec.vocabulary_.iteritems():\n",
    "    embedding_vector = embeddings_index.get(key)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[val] = embedding_vector\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=[-2, -1, 0 , 1, 2])\n",
    "y_train_nn = mlb.fit_transform([[y] for y in y_train])\n",
    "y_test_nn = mlb.transform([[y] for y in y_test])\n",
    "\n",
    "mlb2 = MultiLabelBinarizer(classes=[-1, 0, 1])\n",
    "y_train_nn_ternary = mlb2.fit_transform([[y] for y in y_train_ternary])\n",
    "# y_test_nn = mlb.transform([[y] for y in y_train_task2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import utils \n",
    "class_weights = utils.compute_class_weight('balanced', [-2, -1, 0, 1, 2], y_train)\n",
    "class_weights= {class_id:class_weight for class_id, class_weight in zip(range(5), class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build models...\n"
     ]
    }
   ],
   "source": [
    "print('Build models...')\n",
    "\n",
    "\n",
    "main_input = Input(shape=(MAX_LEN,), dtype='int32', name='main_input')\n",
    "\n",
    "x = Embedding(input_dim = len(vec.vocabulary_)+1, output_dim = EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_LEN, trainable=True, dropout=0.3)(main_input)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "lstm_out = Bidirectional(LSTM(output_dim = 50, input_dim = EMBEDDING_DIM, dropout_W=0.3, dropout_U=0.3) )(x)\n",
    "\n",
    "\n",
    "auxiliary_input = Input(shape=(1368,), name='aux_input')\n",
    "t_auxiliary_input = Dense(256, activation='tanh')(auxiliary_input)\n",
    "t_auxiliary_input = Dropout(0.5)(t_auxiliary_input)\n",
    "\n",
    "x = merge([lstm_out, t_auxiliary_input], mode='concat')\n",
    "\n",
    "\n",
    "x = Dense(30, activation='tanh', )(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "task1_output = Dense(5, activation='softmax', name='main_output')(x)\n",
    "task2_output = Dense(3, activation='softmax', name='aux_output')(x)\n",
    "\n",
    "\n",
    "model_task1 = Model(input=[main_input, auxiliary_input], output=[task1_output])\n",
    "model_task2 = Model(input=[main_input, auxiliary_input], output=[task2_output])\n",
    "\n",
    "model_task1.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_task2.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model_task1.summary()\n",
    "#model_task2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 \tDEV: 1.92295925391 \tTEST: 1.93709559081\n",
      "Iteration: 2 \tDEV: 1.18776405748 \tTEST: 1.05533295264\n",
      "Iteration: 3 \tDEV: 0.895966946297 \tTEST: 0.816812569005\n",
      "Iteration: 4 \tDEV: 1.02211077479 \tTEST: 0.892998712215\n",
      "Iteration: 5 \tDEV: 0.954160935923 \tTEST: 0.826061924628\n",
      "Iteration: 6 \tDEV: 0.924547925944 \tTEST: 0.786129369759\n",
      "Iteration: 7 \tDEV: 0.854076047407 \tTEST: 0.735604932049\n",
      "Iteration: 8 \tDEV: 0.799235732629 \tTEST: 0.657763888703\n",
      "Iteration: 9 \tDEV: 0.833436881142 \tTEST: 0.726908912671\n",
      "Iteration: 10 \tDEV: 0.784366450381 \tTEST: 0.682021796296\n",
      "Iteration: 11 \tDEV: 0.755167897014 \tTEST: 0.665676846315\n",
      "Iteration: 12 \tDEV: 0.81856971338 \tTEST: 0.71937841112\n",
      "Iteration: 13 \tDEV: 0.762962818998 \tTEST: 0.658635105364\n",
      "Iteration: 14 \tDEV: 0.773821181079 \tTEST: 0.708637987154\n",
      "Iteration: 15 \tDEV: 0.775601371349 \tTEST: 0.665637346606\n",
      "Iteration: 16 \tDEV: 0.759631361236 \tTEST: 0.703419706797\n",
      "Iteration: 17 \tDEV: 0.787738085984 \tTEST: 0.751457377915\n",
      "Iteration: 18 \tDEV: 0.804429359786 \tTEST: 0.747156926376\n",
      "Iteration: 19 \tDEV: 0.815791954936 \tTEST: 0.683381326876\n",
      "Iteration: 20 \tDEV: 0.850576735275 \tTEST: 0.756387118012\n",
      "Iteration: 21 \tDEV: 0.790620373789 \tTEST: 0.739320606845\n",
      "Iteration: 22 \tDEV: 0.764482852452 \tTEST: 0.683031976188\n",
      "Iteration: 23 \tDEV: 0.803140795212 \tTEST: 0.725999022617\n",
      "Iteration: 24 \tDEV: 0.808647040185 \tTEST: 0.744529571075\n",
      "Iteration: 25 \tDEV: 0.817937194796 \tTEST: 0.706654354228\n",
      "Iteration: 26 \tDEV: 0.807327637535 \tTEST: 0.768356525751\n",
      "Iteration: 27 \tDEV: 0.861871030075 \tTEST: 0.756031051972\n",
      "Iteration: 28 \tDEV: 0.854804707783 \tTEST: 0.821395129217\n",
      "Iteration: 29 \tDEV: 0.823053542862 \tTEST: 0.783426924025\n",
      "Iteration: 30 \tDEV: 0.844449656178 \tTEST: 0.747247759193\n",
      "Iteration: 31 \tDEV: 0.824878779691 \tTEST: 0.797660345422\n",
      "Iteration: 32 \tDEV: 0.825061301588 \tTEST: 0.767186215062\n",
      "Iteration: 33 \tDEV: 0.83082769645 \tTEST: 0.7776032457\n",
      "Iteration: 34 \tDEV: 0.80440427363 \tTEST: 0.742673350311\n",
      "Iteration: 35 \tDEV: 0.828627354066 \tTEST: 0.744338298501\n",
      "Iteration: 36 \tDEV: 0.819334882033 \tTEST: 0.729371547829\n",
      "Iteration: 37 \tDEV: 0.901746496735 \tTEST: 0.783955756206\n",
      "Iteration: 38 \tDEV: 0.903028631744 \tTEST: 0.752098017949\n",
      "Iteration: 39 \tDEV: 0.795337867354 \tTEST: 0.722056277475\n",
      "Iteration: 40 \tDEV: 0.844048296355 \tTEST: 0.768640202983\n",
      "Iteration: 41 \tDEV: 0.780133585328 \tTEST: 0.741161528006\n",
      "Iteration: 42 \tDEV: 0.803202129502 \tTEST: 0.766803837581\n",
      "Iteration: 43 \tDEV: 0.825221027768 \tTEST: 0.769970364866\n",
      "Iteration: 44 \tDEV: 0.84310632542 \tTEST: 0.787748529746\n",
      "Iteration: 45 \tDEV: 0.829183898124 \tTEST: 0.773112306279\n",
      "Iteration: 46 \tDEV: 0.795794030928 \tTEST: 0.74658846479\n",
      "Iteration: 47 \tDEV: 0.775570256578 \tTEST: 0.737646257549\n",
      "Iteration: 48 \tDEV: 0.817065613571 \tTEST: 0.746390413085\n",
      "Iteration: 49 \tDEV: 0.903140564291 \tTEST: 0.811813157035\n",
      "Iteration: 50 \tDEV: 0.838185184101 \tTEST: 0.750441266774\n",
      "Iteration: 51 \tDEV: 0.871796566588 \tTEST: 0.759380888795\n",
      "Iteration: 52 \tDEV: 0.811734337629 \tTEST: 0.742526685269\n",
      "Iteration: 53 \tDEV: 0.804882941058 \tTEST: 0.746097919402\n",
      "[0.75516789701430687, 0.66567684631518431]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "results = []\n",
    "for batch in range(600*5):\n",
    "    nb_rand = \n",
    "    if random.random() < 1.0:\n",
    "        sample = np.random.randint(0, len(x_train_nn), BATCH_SIZE)\n",
    "        x_sampled, y_sampled, x_aux = x_train_nn[sample], y_train_nn[sample], X_train_additional[sample]\n",
    "        model_task1.train_on_batch({'main_input': x_sampled, 'aux_input': x_aux.todense() }, [y_sampled], class_weight=class_weights, sample_weight=None)\n",
    "    else:\n",
    "        sample = np.random.randint(0, len(x_train_ternary_nn), BATCH_SIZE)\n",
    "        x_sampled, y_sampled, x_aux = x_train_ternary_nn[sample], y_train_nn_ternary[sample], X_ternary_additional[sample]\n",
    "        model_task2.train_on_batch({'main_input': x_sampled, 'aux_input': x_aux.todense()}, [y_sampled], class_weight=None, sample_weight=None)\n",
    "        \n",
    "    if batch%57==0:\n",
    "        dev_preds = np.argmax(model_task1.predict({'main_input': x_dev_nn,'aux_input': X_dev_additional.todense() }, batch_size=BATCH_SIZE, verbose=0), axis=1)\n",
    "        test_preds = np.argmax(model_task1.predict({'main_input': x_test_nn, 'aux_input': X_test_additional.todense()}, batch_size=BATCH_SIZE, verbose=0), axis=1)\n",
    "        results.append([macroMAE(y_dev, dev_preds-2), macroMAE(y_test, test_preds-2)])\n",
    "        print \"Iteration:\", int(batch/57)+1, \"\\tDEV:\", results[-1][0], \"\\tTEST:\", results[-1][1]\n",
    "        \n",
    "#68 0.775022887016 0.778202313573 <- without extra features best\n",
    "#probably need to do some cross-val or increase the size of the validation set.. Increased dropout, helped. !Success!!!\n",
    "best_run = np.argmin(np.asarray(results)[:,0])\n",
    "print results[best_run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
